{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer des bibliothèques\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd \n",
    "import re\n",
    "from io import StringIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste d'URLs vers les pages contenant les données de football à extraire\n",
    "url = ['https://www.kooora.com/?c=1631','https://www.kooora.com/?c=1693',\n",
    "       'https://www.kooora.com/?c=1578','https://www.kooora.com/?c=1574',\n",
    "       'https://www.kooora.com/?c=1573','https://www.kooora.com/?c=1438',\n",
    "       'https://www.kooora.com/?c=1489','https://www.kooora.com/?c=1485',\n",
    "       'https://www.kooora.com/?c=127','https://www.kooora.com/?c=784',\n",
    "       'https://www.kooora.com/?c=1433','https://www.kooora.com/?c=2560',\n",
    "       'https://www.kooora.com/?c=3292','https://www.kooora.com/?c=3968',\n",
    "       'https://www.kooora.com/?c=4752','https://www.kooora.com/?c=5875',\n",
    "       'https://www.kooora.com/?c=7607','https://www.kooora.com/?c=8648',\n",
    "       'https://www.kooora.com/?c=9406','https://www.kooora.com/?c=10693',\n",
    "       'https://www.kooora.com/?c=10392','https://www.kooora.com/?c=13055',\n",
    "       'https://www.kooora.com/?c=14595','https://www.kooora.com/?c=16056',\n",
    "       'https://www.kooora.com/?c=17865','https://www.kooora.com/?c=21404',\n",
    "       'https://www.kooora.com/?c=22826','https://www.kooora.com/?c=24721']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation de la variable de comptage 'i'\n",
    "i = 0\n",
    "# Pour le stocker le dataFrame de chaque annee\n",
    "liste_df_global = []\n",
    "# Boucle pour extraire et traiter les statistiques de classement à partir des liens URL fournis\n",
    "for u in url :\n",
    "    # Faire une requête GET à l'URL u\n",
    "    page = requests.get(u)\n",
    "    # Utilisation de BeautifulSoup pour analyser le contenu HTML de la page obtenue précédemment\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Recherche de toutes les balises <table> dans le contenu HTML analysé\n",
    "    tab = soup.find_all(\"table\")\n",
    "    # Sélection de la deuxième balise <table> de la liste tab\n",
    "    tab =  tab[1]\n",
    "    # Trouver la balise de script contenant rankstable (rankstable c'est la table en JS qui contient les données (objectif))\n",
    "    script_tag = soup.find('script', string=re.compile(r'var rankstable ='))\n",
    "    # Extraire le contenu du script\n",
    "    if script_tag:\n",
    "        script = script_tag.string\n",
    "    else:\n",
    "        print(\"Balise de script introuvable\")\n",
    "    # Définir le motif pour correspondre aux lignes\n",
    "    motif = re.compile(r'^\\s*\"r\",.*$', re.MULTILINE)\n",
    "    # Trouver toutes les correspondances en utilisant le motif\n",
    "    lignes = motif.findall(script)\n",
    "    # Déclaration d'un liste\n",
    "    data = []\n",
    "    # Stocker les lignes correspondantes dans la liste data\n",
    "    for ligne in lignes :\n",
    "        data.append(ligne)\n",
    "    # Créer un flux de texte à partir des données\n",
    "    data_stream = StringIO(\"\\n\".join(data))\n",
    "    # Lire le flux de texte dans une dataframe pandas\n",
    "    df = pd.read_csv(data_stream, header=None)\n",
    "    # Définir les nouveaux noms des colonnes de notre DataFrame\n",
    "    colonnes = {0:\"A\" , 1:\"B\",2:\"Classement\", \n",
    "                3:\"C\", 4:\"Équipe\", 5:\"Matchs Joués\", \n",
    "                6:\"Victoires\", 7:\"Égalités\", 8:\"Défaites\", \n",
    "                9:\"Buts Marqués\", 10:\"Buts Encaissés\", \n",
    "                11:\"Différence de Buts\", 12:\"Points\", \n",
    "                13:\"D\", 14:\"E\"}\n",
    "    # Renommer les colonnes de df\n",
    "    df.rename(columns=colonnes, inplace=True)\n",
    "    # Fonction pour extraire le contenu entre les balises <a>\n",
    "    def extraire_contenu(html):\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        return soup.get_text()\n",
    "    # Modifier le contenu des colonnes spécifiées qui contiennent les balises <a>\n",
    "    colonne_1 = [\"Équipe\", \"Matchs Joués\", \"Victoires\", \"Égalités\", \"Défaites\"]\n",
    "    for colonne in colonne_1 :\n",
    "        df[colonne] = df[colonne].apply(extraire_contenu)\n",
    "    # Nettoyer les colonnes spécifiées et le convertir en int\n",
    "    columns_to_clean = [\"Victoires\", \"Égalités\", \"Défaites\"]\n",
    "    for col in columns_to_clean:\n",
    "        df[col] = df[col].apply(lambda x: int(str(x).replace('\"', '')))\n",
    "        # Modifier la colonne 'classement'\n",
    "    df['Classement'] = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "    # Sélectionner les colonnes utiles et négliger les autres\n",
    "    colonne = [\"Classement\", \"Équipe\", \"Matchs Joués\", \"Victoires\", \"Égalités\", \"Défaites\", \"Buts Marqués\", \"Buts Encaissés\", \"Différence de Buts\", \"Points\"]\n",
    "    df = df[colonne]\n",
    "    points = []\n",
    "    # Modifier les lignes commençant par '<nobr><span' dans la colonne 'points'\n",
    "    for ligne in df['Points'] :\n",
    "        ch = \"<nobr><span\"\n",
    "        if ch in str(ligne) :\n",
    "            ligne = ligne[-3:-1]\n",
    "            points.append(ligne)\n",
    "        else : \n",
    "            points.append(ligne)\n",
    "    df['Points'] = points\n",
    "    # Convertir les colonnes numériques en int\n",
    "    col_ = [\"Classement\", \"Matchs Joués\", \"Victoires\", \"Égalités\", \"Défaites\", \"Buts Marqués\", \"Buts Encaissés\", \"Différence de Buts\", \"Points\"]\n",
    "    for colo in col_:\n",
    "        df[colo] = df[colo].apply(lambda x: int(str(x)))\n",
    "    liste_df_global.append(df)\n",
    "    # Incrémenter l'index pour l'année\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le stockage de classement pour l'année 1995_1996 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 1996_1997 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 1997_1998 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 1998_1999 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 1999_2000 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2000_2001 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2001_2002 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2002_2003 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2003_2004 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2004_2005 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2005_2006 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2006_2007 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2007_2008 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2008_2009 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2009_2010 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2010_2011 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2011_2012 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2012_2013 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2013_2014 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2014_2015 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2015_2016 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2016_2017 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2017_2018 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2018_2019 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2019_2020 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2020_2021 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2021_2022 a été effectué avec succès.\n",
      "Le stockage de classement pour l'année 2022_2023 a été effectué avec succès.\n"
     ]
    }
   ],
   "source": [
    "# Pour enregistrer ces données dans des fichiers Excel\n",
    "annee = ['1995_1996','1996_1997','1997_1998','1998_1999',\n",
    "         '1999_2000','2000_2001','2001_2002','2002_2003',\n",
    "         '2003_2004','2004_2005','2005_2006','2006_2007',\n",
    "         '2007_2008','2008_2009','2009_2010','2010_2011',\n",
    "         '2011_2012','2012_2013','2013_2014','2014_2015',\n",
    "         '2015_2016','2016_2017','2017_2018','2018_2019',\n",
    "         '2019_2020','2020_2021','2021_2022','2022_2023']\n",
    "i = 0\n",
    "chemin = \"C:\\\\Users\\\\HP 840 G6\\\\Desktop\" #Vous pouvez changer le chemin\n",
    "for j in liste_df_global :\n",
    "    j.to_excel(f\"{chemin}\\\\classement_{annee[i]}.xlsx\")\n",
    "    print(f\"Le stockage de classement pour l'année {annee[i]} a été effectué avec succès.\")\n",
    "    i = i + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
